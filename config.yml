fairsin:
    optimize_param:
        hidden: [16, 32, 64, 128, 256]
        gnn_layer_size: [2]
        gnn_hidden: [16, 32, 64, 128, 256]
        cls_layer_size: [2]
        c_lr: [0.01, 0.001, 0.0001, 0.00001]
        e_lr: [0.01, 0.001, 0.0001, 0.00001]
        m_lr: [0.01, 0.001, 0.0001, 0.00001]
        d_lr: [0.01, 0.001, 0.0001, 0.00001]
        delta: [0.5, 1, 5]
        wd: [0.001, 0.0001, 0]
        dropout: [0.2, 0.5, 0.8]
    fixed_param:
        epochs: 50
        d_epochs: 10
        c_epochs: 10
        m_epochs: 20
        d: 'yes'
vanilla:
    optimize_param:
        hidden: [16, 32, 64, 128, 256]
        gnn_layer_size: [2]
        gnn_hidden: [16, 32, 64, 128, 256]
        cls_layer_size: [2]
        lr: [0.01, 0.001, 0.0001, 0.00001]
        weight_decay: [0.01, 0.05, 0.001, 0.002, 0.0001, 0.00001]
fairgnn:
    optimize_param:
        hidden: [16, 32, 64, 128, 256]
        gnn_layer_size: [2]
        gnn_hidden: [16, 32, 64, 128, 256]
        cls_layer_size: [2]
        acc: [0.2, 0.3, 0.4, 0.5, 0.6, 0.68, 0.688, 0.69, 0.7, 0.8, 0.9]
        g_alpha: [1, 2, 3, 4, 5, 6, 7, 10, 20, 40, 50, 100]
        g_beta: [1, 0.1, 0.01, 0.001, 0.0001]
        proj_hidden: [4, 8, 16, 64, 128]
        lr: [0.01, 0.001, 0.0001, 0.00001]
        weight_decay: [0.01, 0.001, 0.0001, 0.00001]
nifty:
    optimize_param:
        hidden: [16, 32, 64, 128, 256]
        gnn_layer_size: [2]
        gnn_hidden: [16, 32, 64, 128, 256]
        cls_layer_size: [2]
        num_proj_hidden: [4, 16, 32, 64, 128, 256]
        lr: [0.01, 0.001, 0.0001, 0.00001]
        weight_decay: [0.01, 0.001, 0.0001, 0.00001, 0.000001]
        sim_coeff: [0.3, 0.4, 0.5, 0.6, 0.7]
        drop_edge_rate_1: [0.1, 0.01, 0.001, 0.0001]
        drop_edge_rate_2: [0.1, 0.01, 0.001, 0.0001]
        drop_feature_rate_1: [0.1, 0.01, 0.001, 0.0001]
        drop_feature_rate_2: [0.1, 0.01, 0.001, 0.0001]

